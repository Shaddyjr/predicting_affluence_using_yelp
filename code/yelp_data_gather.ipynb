{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data\n",
    "\n",
    "---\n",
    "\n",
    "Data gathered from [Yelp Fusion API](https://www.yelp.com/developers/documentation/v3/business_search). The API authorizes a maximum of 5000 daily calls but we did not need to actually pull that many times since the maximum amount of unique pulls is actually 50 datapoints per call.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries to read .json and store the data into a dataframe\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the API Loop to Retrieve Business Data for New York City\n",
    "\n",
    "We define the boroughs below for the API to retrieve business data. Because the API has a cap of 1000 unique data per filter, we had to design multiple calls and aim to retrieve up to 5000 data points. However, this technique will not guarantee every business we gather will be unique. Because there could be duplicate business even if we change the filter, we had to drop duplicates by using business ID as the indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Manhattan', 'Brooklyn', 'Queens', 'Staten Island', 'Bronx']\n",
    "data = []\n",
    "count = 1\n",
    "\n",
    "for city in cities:\n",
    "    for i in range(20):\n",
    "        URL = 'https://api.yelp.com/v3/businesses/search'\n",
    "        API_KEY = '3TjUrfMsEdbVfUKeiU31J7vFJyZp20FKhSg_OJni2TOL_Lo8A9-Z0WG_T3_jFeGzh3-WBtszKN1AAFPuYLh-7mJ7sxP2YdMalw_D5y4ExcXL3c0xUST3Sp-OIGMvXXYx'\n",
    "        params = {'location': city,\n",
    "                  'limit': 50 ,\n",
    "                  'offset': 50 * i}\n",
    "        headers = {'Authorization': 'bearer %s' % API_KEY}\n",
    "        resp = requests.get(url=URL, params = params, headers = headers)\n",
    "        data.extend(resp.json()['businesses'])\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        print(f'Pulling {count} times.')\n",
    "        count += 1\n",
    "        time.sleep(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Gathering\n",
    "\n",
    "We believe that the initial amount of data after applying city filters were not sufficient for our analysis. By applying a zip code search as a filter, we managed to expand the size of our data within Greater New York area by a sizable margin. Below is a search by zip code and by the same methodology, pulling multiple times from the same zip code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of zip codes for the loop to cycle through\n",
    "zip_code_list = [\n",
    " '10464',            \n",
    " '10304',\n",
    " '10028',\n",
    " '11221',\n",
    " '11369',\n",
    " '11104',\n",
    " '10065',\n",
    " '11374',\n",
    " '10310',\n",
    " '11206',\n",
    " '10039',\n",
    " '10473',\n",
    " '11434',\n",
    " '10468',\n",
    " '11233',\n",
    " '10040',\n",
    " '10075',\n",
    " '11418',\n",
    " '10455',\n",
    " '11220',\n",
    " '10302',\n",
    " '11210',\n",
    " '10460',\n",
    " '11370',\n",
    " '11378',\n",
    " '11209',\n",
    " '11102',\n",
    " '10037',\n",
    " '11367',\n",
    " '11232',\n",
    " '11213',\n",
    " '10452',\n",
    " '10471',\n",
    " '11357',\n",
    " '10307',\n",
    " '10456',\n",
    " '11436',\n",
    " '11203',\n",
    " '10801',\n",
    " '10453',\n",
    " '11365',\n",
    " '11356',\n",
    " '10303',\n",
    " '10466',\n",
    " '11234',\n",
    " '10020',\n",
    " '11228',\n",
    " '10004',\n",
    " '11207',\n",
    " '11433',\n",
    " '11432',\n",
    " '11415',\n",
    " '10038',\n",
    " '11366',\n",
    " '10457',\n",
    " '11239',\n",
    " '10710',\n",
    " '11364',\n",
    " '10128',\n",
    " '10459',\n",
    " '10470',\n",
    " '11379',\n",
    " '10474',\n",
    " '10803',\n",
    " '11430',\n",
    " '10007',\n",
    " '11414',\n",
    " '11417',\n",
    " '11421',\n",
    " '11109',\n",
    " '10701',\n",
    " '10550',\n",
    " '11212',\n",
    " '11208',\n",
    " '10006',\n",
    " '11362',\n",
    " '10111',\n",
    " '10708',\n",
    " '10281',\n",
    " '10168',\n",
    " '11236',\n",
    " '10169',\n",
    " '11423',\n",
    " '10704',\n",
    " '11360',\n",
    " '10005',\n",
    " '11412',\n",
    " '10528',\n",
    " '10120',\n",
    " '10176',\n",
    " '10706',\n",
    " '10118',\n",
    " '10552',\n",
    " '10103',\n",
    " '10112',\n",
    " '11241',\n",
    " '10158',\n",
    " '11416',\n",
    " '10080',\n",
    " '11003',\n",
    " '11413',\n",
    " '10121',\n",
    " '10583',\n",
    " '10543',\n",
    " '10705',\n",
    " '10178',\n",
    " '10154',\n",
    " '10311',\n",
    " '10271',\n",
    " '10177',\n",
    " '10553']\n",
    "\n",
    "count = 1\n",
    "for zip_code in zip_code_list:\n",
    "    for i in range(5):\n",
    "        URL = 'https://api.yelp.com/v3/businesses/search'\n",
    "        API_KEY = '3TjUrfMsEdbVfUKeiU31J7vFJyZp20FKhSg_OJni2TOL_Lo8A9-Z0WG_T3_jFeGzh3-WBtszKN1AAFPuYLh-7mJ7sxP2YdMalw_D5y4ExcXL3c0xUST3Sp-OIGMvXXYx'\n",
    "        params = {'location': zip_code,\n",
    "                  'limit': 50,\n",
    "                  'offset': 50 * i}\n",
    "        headers = {'Authorization': 'bearer %s' % API_KEY}\n",
    "        resp = requests.get(url=URL, params = params, headers = headers)\n",
    "        businesses = resp.json()['businesses']\n",
    "        if len(businesses) == 0:\n",
    "            break\n",
    "        data.extend(businesses)\n",
    "        print(f'Pulling {count} times.')\n",
    "        count += 1\n",
    "        time.sleep(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using zip code for additional data, we also use random addresses located around the city as a location point and pull from the API. We used a list of addresses below and let the API give us 1000 results per area near that address. We still have to be wary of duplicates so similar method will be used to remove unwanted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "addresses = ['129 Elmwood Ave, Brooklyn, NY 11230',\n",
    "           '10 E 21st St, New York, NY 10010', \n",
    "           '1 E 161 St, The Bronx, NY 10451', \n",
    "           '123-01 Roosevelt Ave, Queens, NY 11368',\n",
    "           '2800 Victory Blvd, Staten Island, NY 10314']\n",
    "\n",
    "for address in addresses:\n",
    "    for i in range(20):\n",
    "        URL = 'https://api.yelp.com/v3/businesses/search'\n",
    "        API_KEY = '3TjUrfMsEdbVfUKeiU31J7vFJyZp20FKhSg_OJni2TOL_Lo8A9-Z0WG_T3_jFeGzh3-WBtszKN1AAFPuYLh-7mJ7sxP2YdMalw_D5y4ExcXL3c0xUST3Sp-OIGMvXXYx'\n",
    "        params = {'location': address,\n",
    "                  'limit': 50,\n",
    "                  'offset': 50 * i}\n",
    "        headers = {'Authorization': 'bearer %s' % API_KEY}\n",
    "        resp = requests.get(url=URL, params = params, headers = headers)\n",
    "        businesses = resp.json()['businesses']\n",
    "        if len(businesses) == 0:\n",
    "            break\n",
    "        data.extend(businesses)\n",
    "        print(f'Pulling {count} times.')\n",
    "        count += 1\n",
    "        time.sleep(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Data\n",
    "\n",
    "After the data was gathered, we stored the data in a Dataframe and exported the Dataframe into a .csv file. We will then proceed to analyze the data in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = pd.DataFrame(data)\n",
    "nyc.drop_duplicates(subset='id', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check the shape of the data to see how many unique data remain after we discard all duplicate businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the remaining file to a comma delimited file. The file will be labeled raw because no cleaning were performed as of yet and continuation of exploratory data analysis will be processed in the main notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc.to_csv('./data/nyc_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
